config:
  exporters:
    # Data sources: traces, metrics, logs
    # file:
    #   path: ./filename.json

    debug:
      verbosity: detailed

    # Data sources: traces, metrics, logs
    # otlp:
    #   endpoint: http://tempo.tempo.svc:4318
    #   tls:
    #     insecure: true
    #   tls:
    #     cert_file: cert.pem
    #     key_file: cert-key.pem

    # Data sources: traces, metrics
    otlphttp:
      # endpoint:  # The target base URL to send data to
      traces_endpoint: http://tempo.tempo.svc:4318 # The target URL to send trace data to
      # metrics_endpoint:
      # logs_endpoint

    # Data sources: metrics
    # prometheus:
    #   endpoint: "0.0.0.0:8889"
    #   tls:
    #     ca_file: "/path/to/ca.pem"
    #     cert_file: "/path/to/cert.pem"
    #     key_file: "/path/to/key.pem"
    #   namespace: test-space
    #   const_labels:
    #     label1: value1
    #     "another label": spaced value
    #   send_timestamps: true
    #   metric_expiration: 180m
    #   enable_open_metrics: true
    #   add_metric_suffixes: false
    #   resource_to_telemetry_conversion:
    #     enabled: true

  extensions:
    # The health_check extension is mandatory for this chart.
    # Without the health_check extension the collector will fail the readiness and liveliness probes.
    # The health_check extension can be modified, but should never be removed.
    health_check:
      endpoint: ${env:MY_POD_IP}:13133

  processors:
    # Data sources: traces, metrics, logs
    batch: {}
    
    # Default memory limiter configuration for the collector based on k8s resource limits.
    memory_limiter:
      # check_interval is the time between measurements of memory usage.
      check_interval: 5s
      # By default limit_mib is set to 80% of ".Values.resources.limits.memory"
      limit_percentage: 80
      # By default spike_limit_mib is set to 25% of ".Values.resources.limits.memory"
      spike_limit_percentage: 25

  receivers:
    # Data sources: logs
    # fluentforward:
    #   endpoint: ${env:MY_POD_IP}:8006

    # Data sources: metrics
    hostmetrics:
      scrapers:
        cpu:
        disk:
        filesystem:
        load:
        memory:
        network:
        process:
        processes:
        paging:

    # Data sources: traces
    jaeger:
      protocols:
        grpc:
          endpoint: ${env:MY_POD_IP}:14250
        thrift_http:
          endpoint: ${env:MY_POD_IP}:14268
        thrift_compact:
          endpoint: ${env:MY_POD_IP}:6831

    # Data sources: traces, metrics, logs
    # kafka:
    #   protocol_version: 2.0.0

    # Data sources: traces, metrics, logs
    otlp:
      protocols:
        grpc:
          endpoint: ${env:MY_POD_IP}:4317
        http:
          endpoint: ${env:MY_POD_IP}:4318

    # Data sources: metrics
    # prometheus:
    #   config:
    #     scrape_configs:
    #       - job_name: opentelemetry-collector
    #         scrape_interval: 15s
    #         static_configs:
    #           - targets:
    #               - ${env:MY_POD_IP}:8888

    # Data sources: traces          
    # zipkin:
    #   endpoint: ${env:MY_POD_IP}:9411

  service:
    telemetry:
      metrics:
        address: ${env:MY_POD_IP}:8888
    extensions:
      - health_check
    pipelines:
      logs:
        exporters:
          - debug
        processors:
          - memory_limiter
          - batch
        receivers:
          - otlp
      metrics:
        exporters:
          - debug
        processors:
          - memory_limiter
          - batch
        receivers:
          - otlp
          # - prometheus
      traces:
        exporters:
          - otlphttp
        processors:
          - memory_limiter
          - batch
        receivers:
          - otlp
          - jaeger
          # - zipkin

# Configuration for ports
# nodePort is also allowed
ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    hostPort: 4317
    protocol: TCP
    # nodePort: 30317
    appProtocol: grpc
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    hostPort: 4318
    protocol: TCP
  jaeger-compact:
    enabled: true
    containerPort: 6831
    servicePort: 6831
    hostPort: 6831
    protocol: UDP
  jaeger-thrift:
    enabled: true
    containerPort: 14268
    servicePort: 14268
    hostPort: 14268
    protocol: TCP
  jaeger-grpc:
    enabled: true
    containerPort: 14250
    servicePort: 14250
    hostPort: 14250
    protocol: TCP
  zipkin:
    enabled: false
    containerPort: 9411
    servicePort: 9411
    hostPort: 9411
    protocol: TCP
  metrics:
    # The metrics port is disabled by default. However you need to enable the port
    # in order to use the ServiceMonitor (serviceMonitor.enabled) or PodMonitor (podMonitor.enabled).
    enabled: true
    containerPort: 8888
    servicePort: 8888
    protocol: TCP

# podMonitor:
#   # The pod monitor by default scrapes the metrics port.
#   # The metrics port needs to be enabled as well.
#   enabled: false
#   metricsEndpoints:
#     - port: metrics
#       # interval: 15s

#   # additional labels for the PodMonitor
#   extraLabels: {}
#   #   release: kube-prometheus-stack

serviceMonitor:
  # The service monitor by default scrapes the metrics port.
  # The metrics port needs to be enabled as well.
  enabled: true
  metricsEndpoints:
    - port: metrics
      interval: 15s
      scrapeTimeout: 15s

  # additional labels for the ServiceMonitor
  extraLabels:
    release: prometheus
  # Used to set relabeling and metricRelabeling configs on the ServiceMonitor
  # https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
  relabelings: []
  metricRelabelings: []