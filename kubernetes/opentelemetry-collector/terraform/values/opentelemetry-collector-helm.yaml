# mode: daemonset

# presets:
#   logsCollection:
#     enabled: true
#     includeCollectorLogs: true

config:
  exporters:
    # Data sources: traces, metrics, logs
    # file:
    #   path: ./filename.json

    debug:
      verbosity: detailed

    # logging:
    #   logLevel: debug

    # Data sources: traces, metrics, logs
    otlp/tempo:
      endpoint: tempo.tempo.svc:4317
      tls:
        insecure: true
    #   tls:
    #     cert_file: cert.pem
    #     key_file: cert-key.pem
    # otlp:
    #   endpoint: url:4318
    #   tls:
    #     insecure: true
    #   tls:
    #     cert_file: cert.pem
    #     key_file: cert-key.pem

    # Data sources: traces, metrics
    # otlphttp:
      # endpoint: https://url:4318 # The target base URL to send data to      
      # To send each signal a corresponding path will be added to this base URL, i.e. for traces "/v1/traces" will appended, for metrics "/v1/metrics" will be appended, for logs "/v1/logs" will be appended.
      # traces_endpoint: # The target URL to send trace data to -> https://url:4318/v1/traces. If this setting is present the endpoint setting is ignored for traces
      # metrics_endpoint: # The target URL to send metric data to -> https://url:4318/v1/metrics. If this setting is present the endpoint setting is ignored for metrics
      # logs_endpointL # The target URL to send log data to -> https://url:4318/v1/logs. If this setting is present the endpoint setting is ignored logs

    # otlphttp/tempo:
    #   endpoint: http://tempo.tempo.svc:4318
    #   tls:
    #     insecure: true

    otlphttp/loki:
      # auth:
      #   authenticator: basicauth/loki
      endpoint: http://loki.loki.svc:3100/otlp
      tls:
        insecure: true

    otlphttp/prometheus:
      # otlp write receiver needs to be enabled with --web.enable-otlp-receiver
      endpoint: http://prometheus-operated.monitoring.svc:9090/api/v1/otlp
      # metrics_endpoint: http://prometheus-operated.monitoring.svc:9090/api/v1/otlp/v1/metrics
      # tls:
      #   insecure: true

    # loki:
    #   # auth:
    #   #   authenticator: basicauth/loki
    #   endpoint: https://loki.example.com:3100/loki/api/v1/push
    #   # tls:
    #   #   insecure: true
    #   # default_labels_enabled:
    #   #   exporter: true
    #   #   job: true

    # Data sources: metrics
    # prometheus:
    #   endpoint: "${env:MY_POD_IP}:8889"
    #   # tls:
    #   #   ca_file: "/path/to/ca.pem"
    #   #   cert_file: "/path/to/cert.pem"
    #   #   key_file: "/path/to/key.pem"
    #   namespace: test-space
    #   const_labels:
    #     label1: value1
    #     "another label": spaced value
    #   send_timestamps: true
    #   metric_expiration: 180m
    #   enable_open_metrics: true
    #   add_metric_suffixes: false
    #   resource_to_telemetry_conversion:
    #     enabled: true

  extensions:
    # The health_check extension is mandatory for this chart.
    # Without the health_check extension the collector will fail the readiness and liveliness probes.
    # The health_check extension can be modified, but should never be removed.
    health_check:
      endpoint: ${env:MY_POD_IP}:13133

  processors:
    # Data sources: traces, metrics, logs
    batch: {}
    
    # Default memory limiter configuration for the collector based on k8s resource limits.
    memory_limiter:
      # check_interval is the time between measurements of memory usage.
      check_interval: 5s
      # By default limit_mib is set to 80% of ".Values.resources.limits.memory"
      limit_percentage: 80
      # By default spike_limit_mib is set to 25% of ".Values.resources.limits.memory"
      spike_limit_percentage: 25

  receivers:
    # Data sources: logs
    # fluentforward:
    #   endpoint: ${env:MY_POD_IP}:8006

    # Data sources: metrics
    # hostmetrics:
    #   scrapers:
    #     cpu:
    #     disk:
    #     filesystem:
    #     load:
    #     memory:
    #     network:
    #     process:
    #     processes:
    #     paging:

    # Data sources: traces
    jaeger:
      protocols:
        grpc:
          endpoint: ${env:MY_POD_IP}:14250
        thrift_http:
          endpoint: ${env:MY_POD_IP}:14268
        thrift_compact:
          endpoint: ${env:MY_POD_IP}:6831

    # Data sources: traces, metrics, logs
    # kafka:
    #   protocol_version: 2.0.0

    # Data sources: traces, metrics, logs
    otlp:
      protocols:
        grpc:
          endpoint: ${env:MY_POD_IP}:4317
        http:
          endpoint: ${env:MY_POD_IP}:4318
          cors:
            allowed_origins:
              - "http://*"
              - "https://*"

    # Data sources: metrics
    prometheus:
      config:
        scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            static_configs:
              - targets:
                  - ${env:MY_POD_IP}:8888

    # Data sources: traces          
    # zipkin:
    #   endpoint: ${env:MY_POD_IP}:9411

  service:
    telemetry:
      metrics:
        address: ${env:MY_POD_IP}:8888
      # logs:
      #   level: debug
    extensions:
      - health_check
    pipelines:
      logs:
        exporters:
          # - debug
          - otlphttp/loki
        processors:
          - memory_limiter
          - batch
        receivers:
          - otlp
      metrics:
        exporters:
          # - debug
          - otlphttp/prometheus
        processors:
          - memory_limiter
          - batch
        receivers:
          - otlp
          # - prometheus
      traces:
        exporters:
          - otlp/tempo
        processors:
          - memory_limiter
          - batch
        receivers:
          - otlp
          # - jaeger
          # - zipkin

# Configuration for ports
# nodePort is also allowed
ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    hostPort: 4317
    protocol: TCP
    # nodePort: 30317
    appProtocol: grpc
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    hostPort: 4318
    protocol: TCP
  jaeger-compact:
    enabled: true
    containerPort: 6831
    servicePort: 6831
    hostPort: 6831
    protocol: UDP
  jaeger-thrift:
    enabled: true
    containerPort: 14268
    servicePort: 14268
    hostPort: 14268
    protocol: TCP
  jaeger-grpc:
    enabled: true
    containerPort: 14250
    servicePort: 14250
    hostPort: 14250
    protocol: TCP
  zipkin:
    enabled: false
    containerPort: 9411
    servicePort: 9411
    hostPort: 9411
    protocol: TCP
  metrics:
    # The metrics port is disabled by default. However you need to enable the port
    # in order to use the ServiceMonitor (serviceMonitor.enabled) or PodMonitor (podMonitor.enabled).
    enabled: true
    containerPort: 8888
    servicePort: 8888
    protocol: TCP

# podMonitor:
#   # The pod monitor by default scrapes the metrics port.
#   # The metrics port needs to be enabled as well.
#   enabled: false
#   metricsEndpoints:
#     - port: metrics
#       # interval: 15s

#   # additional labels for the PodMonitor
#   extraLabels: {}
#   #   release: kube-prometheus-stack

serviceMonitor:
  # The service monitor by default scrapes the metrics port.
  # The metrics port needs to be enabled as well.
  enabled: true
  metricsEndpoints:
    - port: metrics
      interval: 15s
      scrapeTimeout: 15s

  # additional labels for the ServiceMonitor
  extraLabels:
    release: prometheus
  # Used to set relabeling and metricRelabeling configs on the ServiceMonitor
  # https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
  relabelings: []
  metricRelabelings: []